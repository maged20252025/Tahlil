
import streamlit as st
import os
import re
import io
import base64
import docx2txt
import fitz  # PyMuPDF

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="ðŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù…Ø­ÙƒÙ…Ø© Ø§Ù„Ø¹Ù„ÙŠØ§", layout="wide")
st.title("ðŸ” Ø£Ø¯Ø§Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ù„ÙØ§Øª PDF Ùˆ Word")

# Ø¯Ø§Ù„Ø© Ù„ØªÙˆØ­ÙŠØ¯ Ø§Ù„Ù†Øµ (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„ ÙˆØ§Ù„Ù…Ø¯ÙˆØ¯)
def normalize_text(text):
    text = re.sub(r'[ÙŽÙ‹ÙÙŒÙÙÙ’Ù‘Ù€]', '', text)  # Remove diacritics
    text = re.sub(r'[Ù€]', '', text)  # Remove tatweel
    return text

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
uploaded_files = st.file_uploader("ðŸ“‚ Ù‚Ù… Ø¨Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª (Word Ø£Ùˆ PDF)", type=["pdf", "docx"], accept_multiple_files=True)

st.markdown("### ðŸ“ ÙˆØµÙ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ")
description = st.text_area("Ø§ÙƒØªØ¨ ÙˆØµÙÙ‹Ø§ ØªÙØµÙŠÙ„ÙŠÙ‹Ø§ Ø¹Ù† Ù†ÙˆØ¹ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„ØªÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡Ø§", height=150)

keywords = st.text_input("ðŸ”‘ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (Ø§ÙØµÙ„ Ø¨ÙŠÙ†Ù‡Ø§ Ø¨ÙØ§ØµÙ„Ø©)")

if st.button("Ø§Ø¨Ø¯Ø£ Ø§Ù„Ø¨Ø­Ø«"):
    if not uploaded_files:
        st.warning("ÙŠØ±Ø¬Ù‰ Ø±ÙØ¹ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª.")
        st.stop()

    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ù…Ù† Ù…Ø±Ø¨Ø¹ Ø§Ù„ÙˆØµÙ + Ù…Ø±Ø¨Ø¹ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ©
    description_words = [w.strip(".,ØŒØŸ:Ø›") for w in description.split() if len(w) > 1]
    raw_keywords = [k.strip() for k in keywords.split(",") if k.strip()]
    all_keywords = list(set(raw_keywords + description_words))
    keyword_list = [normalize_text(k) for k in all_keywords]

    total_hits = 0
    matched_files = []

    for file in uploaded_files:
        file_text = ""
        if file.name.endswith(".pdf"):
            with fitz.open(stream=file.read(), filetype="pdf") as doc:
                for page in doc:
                    file_text += page.get_text()
        elif file.name.endswith(".docx"):
            file_text = docx2txt.process(file)

        normalized_text = normalize_text(file_text)
        matches = []

        for kw in keyword_list:
            spans = re.findall(rf"(.{{0,40}}{re.escape(kw)}.{{0,40}})", normalized_text)
            matches.extend(spans)

        if matches:
            matched_files.append((file.name, matches))
            total_hits += len(matches)

    # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    if matched_files:
        st.success(f"ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {total_hits} Ù†ØªÙŠØ¬Ø© ÙÙŠ {len(matched_files)} Ù…Ù„Ù.")
        for fname, results in matched_files:
            st.markdown(f"### ðŸ“„ {fname}")
            for res in results:
                highlighted = res
                for kw in keyword_list:
                    highlighted = re.sub(f"({re.escape(kw)})", r"**ðŸŸ¨\1ðŸŸ¨**", highlighted, flags=re.IGNORECASE)
                st.markdown(f"> {highlighted}")
            st.markdown("---")
    else:
        st.info("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ù…Ø·Ø§Ø¨Ù‚Ø©.")
